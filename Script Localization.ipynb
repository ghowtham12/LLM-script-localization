{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8860cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gradio\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988bd8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7887\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7887/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import openai\n",
    "import docx\n",
    "import spacy\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set your OpenAI API key\n",
    "openai.api_key =  \"OPEN_API_KEY\"\n",
    "\n",
    "\n",
    "def split_document_into_segments(document_text, max_tokens_per_segment):\n",
    "    segments = []\n",
    "    current_segment = \"\"\n",
    "    \n",
    "    for paragraph in document_text.split(\"\\n\"):\n",
    "        if len(current_segment) + len(paragraph) < max_tokens_per_segment:\n",
    "            current_segment += paragraph + \"\\n\"\n",
    "        else:\n",
    "            segments.append(current_segment)\n",
    "            current_segment = paragraph + \"\\n\"\n",
    "    \n",
    "    if current_segment:\n",
    "        segments.append(current_segment)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "def translate_document_segment(segment, target_language):\n",
    "    prompt = f\"Translate the following segment to {target_language}:\\n{segment}\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=2000  # Adjust the value based on your plan's token limit\n",
    "    )\n",
    "    translated_segment = response.choices[0].text.strip()\n",
    "    return translated_segment\n",
    "\n",
    "def document_translation_interface(docx_file, target_language):\n",
    "    document_text = docx_file.read().decode('utf-8')\n",
    "    \n",
    "    max_tokens_per_segment = 2000  # Adjust the value based on your plan's token limit\n",
    "    \n",
    "    segments = split_document_into_segments(document_text, max_tokens_per_segment)\n",
    "    \n",
    "    translated_segments = []\n",
    "    for segment in segments:\n",
    "        translated_segment = translate_document_segment(segment, target_language)\n",
    "        translated_segments.append(translated_segment)\n",
    "    \n",
    "    translated_document = \"\\n\".join(translated_segments)\n",
    "    \n",
    "    # Save the translated document to a temporary file\n",
    "    translated_filename = \"translated_document.txt\"\n",
    "    with open(translated_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(translated_document)\n",
    "    \n",
    "    return translated_filename\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    content = \"\"\n",
    "    for paragraph in doc.paragraphs:\n",
    "        content += paragraph.text + \"\\n\"\n",
    "    return content\n",
    "\n",
    "# Define a function to find and replace names\n",
    "def find_names(docx_path):\n",
    "    \n",
    "    document_text = extract_text_from_docx(docx_path)\n",
    "        # Process the document text\n",
    "    doc = nlp(document_text)\n",
    "\n",
    "        # Extract named entities of the \"PERSON\" type from the document\n",
    "    names = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\" ]\n",
    "    return names\n",
    "def replace_names_in(docx_path, json_replacements):\n",
    "    # Load the JSON data\n",
    "    try:\n",
    "        replacements = json.loads(json_replacements)\n",
    "    except json.JSONDecodeError as e:\n",
    "        return f\"Error: Invalid JSON format - {str(e)}\"\n",
    "\n",
    "    # Iterate through the names and replacements\n",
    "    text = extract_text_from_docx(docx_path)\n",
    "    for old_name, new_name in replacements.items():\n",
    "        # Replace all occurrences of old_name with new_name in the text\n",
    "        text = text.replace(old_name, new_name)\n",
    "    \n",
    "    updated_filename = \"text.txt\"\n",
    "    with open(updated_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text)\n",
    "    \n",
    "    return updated_filename\n",
    "with gr.Blocks() as demo:\n",
    "    docx_path= gr.Textbox(label=\"Enter Document Path\")\n",
    "    target_language = gr.Radio([\"Spanish\", \"French\", \"German\"], label=\"Target Language\")\n",
    "    translated_document=gr.File(label=\"translated Document\")\n",
    "    translate_btn = gr.Button('Translate')\n",
    "    translate_btn.click(fn=document_translation_interface, inputs=[docx_path,target_language], outputs=translated_document, api_name=\"Translate\")\n",
    "    doc_path= gr.Textbox(label=\"doc_path\")\n",
    "    name = gr.Textbox(label=\"name\")\n",
    "    greet_btn = gr.Button(\"find_names\")\n",
    "    greet_btn.click(fn=find_names, inputs=doc_path, outputs=name, api_name=\"find_names\")\n",
    "    doc_path= gr.Textbox(label=\"doc_path\")\n",
    "    replacement = gr.Textbox(label=\"New Names (JSON format)\")\n",
    "    updated_document=gr.File(label=\"Updated Document\")\n",
    "    replace_btn = gr.Button(\"replace_names\")\n",
    "    replace_btn.click(fn=replace_names_in, inputs=[doc_path,replacement], outputs=updated_document, api_name=\"replace_names\")\n",
    "\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9fbba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
